{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f6479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#     Generate Robust Feature set and FacePrint for each session from individual openface metric files\n",
    "#\n",
    "# Change the directories and patient naming conventions to match your setup.\n",
    "#\n",
    "# Author: Stephen Heisig\n",
    "#\n",
    "#\n",
    "from __future__ import division\n",
    "#from sqlalchemy import *\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "#import platform\n",
    "import pipes\n",
    "import re\n",
    "import traceback\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import time, datetime\n",
    "import seaborn as sns\n",
    "import sklearn.cluster as cluster\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.io.wavfile\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "from collections import Counter\n",
    "import pingouin as pg\n",
    "\n",
    "\n",
    "# Input parameters: these are typically set based on the directory structure and file naming of the input\n",
    "# dataset. \n",
    "#N.B. If you change any of these fields the data will not readily join with other users.\n",
    "Diag = 'TRD'\n",
    "Session = 'Monday'\n",
    "Participant = 'MAP_1122'\n",
    "Speakers = ['participant','interviewer']\n",
    "\n",
    "\n",
    "InputDataDir = '/Users/Heisig/Library/CloudStorage/OneDrive-TheMountSinaiHospital/TRD_Mayberg-Murrough_Share/Results/'+Participant+'/'\n",
    "study = 'Test'\n",
    "\n",
    "print('genRobustFaceStats Leap V0.0')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Action Unit definitions...\n",
    "AU number\tFACS name\tMuscular basis\n",
    "0\tNeutral face\t\n",
    "1\tInner brow raiser\tfrontalis (pars medialis)\n",
    "2\tOuter brow raiser\tfrontalis (pars lateralis)\n",
    "4\tBrow lowerer\tdepressor glabellae, depressor supercilii, corrugator supercilii\n",
    "5\tUpper lid raiser\tlevator palpebrae superioris, superior tarsal muscle\n",
    "6\tCheek raiser\torbicularis oculi (pars orbitalis)\n",
    "7\tLid tightener\torbicularis oculi (pars palpebralis)\n",
    "8\tLips toward each other\torbicularis oris\n",
    "9\tNose wrinkler\tlevator labii superioris alaeque nasi\n",
    "10\tUpper lip raiser\tlevator labii superioris, caput infraorbitalis\n",
    "11\tNasolabial deepener\tzygomaticus minor\n",
    "12\tLip corner puller\tzygomaticus major\n",
    "13\tSharp lip puller\tlevator anguli oris (also known as caninus)\n",
    "14\tDimpler\tbuccinator\n",
    "15\tLip corner depressor\tdepressor anguli oris (also known as triangularis)\n",
    "16\tLower lip depressor\tdepressor labii inferioris\n",
    "17\tChin raiser\tmentalis\n",
    "18\tLip pucker\tincisivii labii superioris and incisivii labii inferioris\n",
    "19\tTongue show\t\n",
    "20\tLip stretcher\trisorius w/ platysma\n",
    "21\tNeck tightener\tplatysma\n",
    "22\tLip funneler\torbicularis oris\n",
    "23\tLip tightener\torbicularis oris\n",
    "24\tLip pressor\torbicularis oris\n",
    "25\tLips part\tdepressor labii inferioris, or relaxation of mentalis or orbicularis oris\n",
    "26\tJaw drop\tmasseter; relaxed temporalis and internal pterygoid\n",
    "27\tMouth stretch\tpterygoids, digastric\n",
    "28\tLip suck\torbicularis oris\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}\n",
    "\n",
    "np.set_printoptions(precision=16)  \n",
    "np.set_printoptions(threshold=1000)\n",
    "\n",
    "\n",
    "#N.B. This is a bit confusing but the columns called gaze_angle_x and gaze_angle_y\n",
    "# aren't really angles but are radians\n",
    "# pose_Rx, pose_Ry, pose_Rz This can be seen as pitch (Rx), yaw (Ry), and roll (Rz) of the head box\n",
    "#These columns are radians\n",
    "gazeCols = ['frame',\n",
    "            'face_id',\n",
    "            'confidence',\n",
    "            'success',\n",
    "            'gaze_angle_x',\n",
    "            'gaze_angle_y',\n",
    "            'pose_Rx',\n",
    "            'pose_Ry',\n",
    "            'pose_Rz',\n",
    "            'AU01_r',\n",
    "            'AU02_r',\n",
    "            'AU04_r',\n",
    "            'AU05_r',\n",
    "            'AU06_r',\n",
    "            'AU07_r',\n",
    "            'AU09_r',\n",
    "            'AU10_r',\n",
    "            'AU12_r',\n",
    "            'AU14_r',\n",
    "            'AU15_r',\n",
    "            'AU17_r',\n",
    "            'AU20_r',\n",
    "            'AU23_r',\n",
    "            'AU25_r',\n",
    "            'AU26_r',\n",
    "            'AU45_r',\n",
    "            'AU01_c',\n",
    "            'AU02_c',\n",
    "            'AU04_c',\n",
    "            'AU05_c',\n",
    "            'AU06_c',\n",
    "            'AU07_c',\n",
    "            'AU09_c',\n",
    "            'AU10_c',\n",
    "            'AU12_c',\n",
    "            'AU14_c',\n",
    "            'AU15_c',\n",
    "            'AU17_c',\n",
    "            'AU20_c',\n",
    "            'AU23_c',\n",
    "            'AU25_c',\n",
    "            'AU26_c',\n",
    "            'AU45_c']\n",
    "               \n",
    "newGazeCols = ['frame',\n",
    "            'face_id',\n",
    "            'confidence',\n",
    "            'success',\n",
    "            'gaze_Rx',\n",
    "            'gaze_Ry',\n",
    "            'pose_Rx',\n",
    "            'pose_Ry',\n",
    "            'pose_Rz',\n",
    "            'AU01_int',\n",
    "            'AU02_int',\n",
    "            'AU04_int',\n",
    "            'AU05_int',\n",
    "            'AU06_int',\n",
    "            'AU07_int',\n",
    "            'AU09_int',\n",
    "            'AU10_int',\n",
    "            'AU12_int',\n",
    "            'AU14_int',\n",
    "            'AU15_int',\n",
    "            'AU17_int',\n",
    "            'AU20_int',\n",
    "            'AU23_int',\n",
    "            'AU25_int',\n",
    "            'AU26_int',\n",
    "            'AU45_int',\n",
    "            'AU01_p',\n",
    "            'AU02_p',\n",
    "            'AU04_p',\n",
    "            'AU05_p',\n",
    "            'AU06_p',\n",
    "            'AU07_p',\n",
    "            'AU09_p',\n",
    "            'AU10_p',\n",
    "            'AU12_p',\n",
    "            'AU14_p',\n",
    "            'AU15_p',\n",
    "            'AU17_p',\n",
    "            'AU20_p',\n",
    "            'AU23_p',\n",
    "            'AU25_p',\n",
    "            'AU26_p',\n",
    "            'AU45_p'] \n",
    "\n",
    "#This procedure does a np.diff type function but if there are gaps\n",
    "#as defined by 0 entries in the success series it will discard the 'BAD'\n",
    "#entries (meaning the ones which involved an unsuccessful entry) The idea\n",
    "#is that openface metric entries for frames where the face wasn't successfully tracked \n",
    "#will be excluded from the diff result.              \n",
    "def gapDiff(metric_series,successes_series):\n",
    "    diff_series = np.diff(metric_series)\n",
    "    mask1 = successes_series.iloc[1:]\n",
    "    mask2 = successes_series.iloc[0:-1]\n",
    "    mask1.reset_index(inplace=True, drop=True)\n",
    "    mask2.reset_index(inplace=True, drop=True)\n",
    "    gapMask = mask1.multiply(mask2) \n",
    "    theNoGapDiff = diff_series[gapMask==1] \n",
    "    return [diff_series,gapMask]\n",
    "    \n",
    "def computeBasicFeatures(successful_metrics,metric_name):\n",
    "    featureSuffixes = ['_Mean','_Var','_Kur','_Skew','_Median','_qtl05','_qtl50','_qtl95' ]\n",
    "    absFeatures = ['Vel', 'Accel', 'Jerk']\n",
    "    featureNames = [metric_name+s for s in featureSuffixes]\n",
    "    if metric_name.split('_')[-1] in absFeatures:\n",
    "         mean = np.mean(np.absolute(successful_metrics))\n",
    "    else:\n",
    "        mean = np.mean(successful_metrics)\n",
    "    var = np.var(successful_metrics)\n",
    "    median = np.median(successful_metrics)\n",
    "    kur = sp.stats.kurtosis(successful_metrics)\n",
    "    skew = sp.stats.skew(successful_metrics)\n",
    "    qtl05 = np.quantile(successful_metrics, .05)\n",
    "    qtl50 = np.quantile(successful_metrics, .50)\n",
    "    qtl95 = np.quantile(successful_metrics, .95)      \n",
    "    features = [ mean, var, kur, skew, median, qtl05, qtl50, qtl95 ]\n",
    "    print('basicFeatureNames: \\n',featureNames)\n",
    "    print('basicFeatures: \\n',features)\n",
    "    return [features,featureNames]  \n",
    "    \n",
    "#Given a dataFrame column generate and return the list of robust features    \n",
    "# Ex metrics = genMotionFeatures(gazeDF['gaze_angle_x'],'gaze_Rx')\n",
    "def genRobustMotionFeatures(metric_series,success_series,metric_name):\n",
    "    featureSet = []\n",
    "    featureNameSet = []\n",
    "    featureSuffixes = ['_Mean','_Var','_Kur','_Skew','_Median','_qtl05','_qtl50','_qtl95' ]\n",
    "    featureNames = [metric_name+s for s in featureSuffixes]\n",
    "    successful_metrics = metric_series[success_series==1]\n",
    "    #print('successful_metrics: \\n',successful_metrics)\n",
    "    basicFeatures, basicFeatureNames = computeBasicFeatures(successful_metrics,metric_name)\n",
    "    featureSet.extend(basicFeatures)\n",
    "    featureNameSet.extend(basicFeatureNames)\n",
    "    successful_timestamps = timestamps[success_series==1]\n",
    "    gradient1 =  np.gradient(successful_metrics, successful_timestamps)/30.0\n",
    "    gradient2 =  np.gradient(gradient1, successful_timestamps)/30.0\n",
    "    gradient3 =  np.gradient(gradient2, successful_timestamps)/30.0\n",
    "    #Savitsky-Golay Filter the raw data to remove jitter\n",
    "    windowLen = 13\n",
    "    polynomial = 2\n",
    "    successful_metrics_sg_filtered = savgol_filter(successful_metrics , windowLen, polynomial)\n",
    "    #SJH TODO Why is this here: /30.0  ????????\n",
    "    gradient1_sg_filtered =  np.gradient(successful_metrics_sg_filtered, successful_timestamps)/30.0\n",
    "    gradient2_sg_filtered =  np.gradient(gradient1_sg_filtered, successful_timestamps)/30.0\n",
    "    gradient3_sg_filtered =  np.gradient(gradient2_sg_filtered, successful_timestamps)/30.0 \n",
    "    \n",
    "    [velocity,velMask] = gapDiff(metric_series,success_series)\n",
    "    noGapVelocity = velocity[velMask==1] \n",
    "    #print('np.absolute(noGapVelocity): \\n',np.absolute(noGapVelocity))\n",
    "    velMetricName = metric_name+'_Vel'\n",
    "    basicFeatures, basicFeatureNames = computeBasicFeatures(noGapVelocity,velMetricName)\n",
    "    featureSet.extend(basicFeatures)\n",
    "    featureNameSet.extend(basicFeatureNames)\n",
    "    \n",
    "    meanVel = np.mean(np.absolute(noGapVelocity))\n",
    "    [accel,accelMask] = gapDiff(velocity,velMask)\n",
    "    #print('accel: \\n',accel)\n",
    "    #print('accelMask: \\n',accelMask)\n",
    "    \n",
    "    noGapAccel = accel[accelMask==1] \n",
    "    print('np.absolute(noGapAccel): \\n',np.absolute(noGapAccel))\n",
    "    meanAccel = np.mean(np.absolute(noGapAccel))\n",
    "    accelMetricName = metric_name+'_Accel'\n",
    "    basicFeatures, basicFeatureNames = computeBasicFeatures(noGapAccel,accelMetricName)\n",
    "    featureSet.extend(basicFeatures)\n",
    "    featureNameSet.extend(basicFeatureNames)\n",
    "    \n",
    "    [jerk,jerkMask] = gapDiff(accel,accelMask)\n",
    "    #print('jerk: \\n',jerk)\n",
    "    #print('jerkMask: \\n',jerkMask)\n",
    "    \n",
    "    noGapJerk = jerk[jerkMask==1] \n",
    "    print('np.absolute(noGapJerk): \\n',np.absolute(noGapJerk))\n",
    "    meanJerk = np.mean(np.absolute(noGapJerk))\n",
    "    jerkMetricName = metric_name+'_Jerk'\n",
    "    basicFeatures, basicFeatureNames = computeBasicFeatures(noGapJerk,jerkMetricName)\n",
    "    featureSet.extend(basicFeatures)\n",
    "    featureNameSet.extend(basicFeatureNames)\n",
    "    \n",
    "    print('successful_metrics.shape,noGapVelocity.shape,noGapJerk.shape,noGapAccel.shape: ',successful_metrics.shape,noGapVelocity.shape,noGapJerk.shape,noGapAccel.shape)\n",
    "    print('type(successful_metrics): ',type(successful_metrics))\n",
    "    print('type(noGapVelocity): ',type(noGapVelocity))\n",
    "    #successful_metricsDF = pd.DataFrame(successful_metrics,columns=['metric'])\n",
    "    noGapVelocityDF = pd.DataFrame(noGapVelocity,columns=['noGapVelocity'])\n",
    "    noGapAccelDF = pd.DataFrame(noGapAccel,columns=['noGapAccel'])\n",
    "    noGapJerkDF = pd.DataFrame(noGapJerk,columns=['noGapJerk'])\n",
    "    gradient1DF = pd.DataFrame(gradient1,columns=['gradient1'])\n",
    "    gradient2DF = pd.DataFrame(gradient2,columns=['gradient2'])\n",
    "    gradient3DF = pd.DataFrame(gradient3,columns=['gradient3'])\n",
    "    successful_metrics_sg_filteredDF = pd.DataFrame(successful_metrics_sg_filtered,columns=['successful_metrics_sg_filtered'])\n",
    "    gradient1_sg_filteredDF = pd.DataFrame(gradient1_sg_filtered,columns=['gradient1_sg_filtered'])\n",
    "    gradient2_sg_filteredDF = pd.DataFrame(gradient2_sg_filtered,columns=['gradient2_sg_filtered'])\n",
    "    gradient3_sg_filteredDF = pd.DataFrame(gradient3_sg_filtered,columns=['gradient3_sg_filtered'])\n",
    "    print('successful_metrics.shape,noGapVelocityDF.shape,noGapJerkDF.shape,noGapAccelDF.shape: ',successful_metrics.shape,noGapVelocity.shape,noGapJerk.shape,noGapAccel.shape)\n",
    "    allNoGapDF = pd.concat([successful_metrics,successful_metrics_sg_filteredDF,noGapVelocityDF,noGapAccelDF,noGapJerkDF,gradient1DF,gradient2DF,gradient3DF,gradient1_sg_filteredDF,gradient2_sg_filteredDF,gradient3_sg_filteredDF], axis=1)\n",
    "    allNoGapDF.columns = ['successful_metric','successful_metrics_sg_filtered','noGapVelocity','noGapAccel','noGapJerk','gradient1','gradient2','gradient3','gradient1_sg_filtered','gradient2_sg_filtered','gradient3_sg_filtered']\n",
    "    #noGapFileName = noGapFileDir+Session+\"_\"+metric_name+\"_noGapVelAccelJerk.csv\"\n",
    "    #allNoGapDF.to_csv(noGapFileName, index=False)\n",
    "\n",
    "    return [featureSet,featureNameSet]    \n",
    "\n",
    "#Generate correlation features    \n",
    "def genFacePrint(gazeDF,features,featureNames):\n",
    "\n",
    "    #Calculate Activity features \n",
    "    featIndices = []\n",
    "    #Explicitly state and find the feature name indices   \n",
    "    corrFeaturesList1 = ['gaze_Rx_Vel_Mean', 'gaze_Ry_Vel_Mean', 'pose_Rx_Vel_Mean', 'pose_Ry_Vel_Mean', 'pose_Rz_Vel_Mean', \n",
    "                        'AU01_int_Mean', 'AU02_int_Mean', 'AU04_int_Mean', 'AU05_int_Mean', 'AU06_int_Mean', \n",
    "                        'AU07_int_Mean', 'AU09_int_Mean', 'AU10_int_Mean', 'AU12_int_Mean', 'AU14_int_Mean', 'AU15_int_Mean', \n",
    "                        'AU17_int_Mean', 'AU20_int_Mean', 'AU23_int_Mean', 'AU25_int_Mean', 'AU26_int_Mean', 'AU45_int_Mean', \n",
    "                        'AU01_p_PerCent', 'AU02_p_PerCent', 'AU04_p_PerCent', 'AU05_p_PerCent', 'AU06_p_PerCent', 'AU07_p_PerCent', 'AU09_p_PerCent', \n",
    "                        'AU10_p_PerCent', 'AU12_p_PerCent', 'AU14_p_PerCent', 'AU15_p_PerCent', 'AU17_p_PerCent', 'AU20_p_PerCent', 'AU23_p_PerCent',\n",
    "                        'AU25_p_PerCent', 'AU26_p_PerCent', 'AU45_p_PerCent']\n",
    "    corrFeaturesList2 = ['gaze_Rx_Vel_Mean', 'gaze_Ry_Vel_Mean', 'pose_Rx_Vel_Mean', 'pose_Ry_Vel_Mean', 'pose_Rz_Vel_Mean', \n",
    "                        'AU01_int_qtl90', 'AU02_int_qtl90', 'AU04_int_qtl90', 'AU05_int_qtl90', 'AU06_int_qtl90', \n",
    "                        'AU07_int_qtl90', 'AU09_int_qtl90', 'AU10_int_qtl90', 'AU12_int_qtl90', 'AU14_int_qtl90', 'AU15_int_qtl90', \n",
    "                        'AU17_int_qtl90', 'AU20_int_qtl90', 'AU23_int_qtl90', 'AU25_int_qtl90', 'AU26_int_qtl90', 'AU45_int_qtl90', \n",
    "                        'AU01_p_PerCent', 'AU02_p_PerCent', 'AU04_p_PerCent', 'AU05_p_PerCent', 'AU06_p_PerCent', 'AU07_p_PerCent', 'AU09_p_PerCent', \n",
    "                        'AU10_p_PerCent', 'AU12_p_PerCent', 'AU14_p_PerCent', 'AU15_p_PerCent', 'AU17_p_PerCent', 'AU20_p_PerCent', 'AU23_p_PerCent',\n",
    "                        'AU25_p_PerCent', 'AU26_p_PerCent', 'AU45_p_PerCent']\n",
    "    #print('featureNames: \\n',featureNames)\n",
    "    for feat in corrFeaturesList2:\n",
    "        featIndices.append(featureNames.index(feat))\n",
    "        \n",
    "    testFeatureNames = [featureNames[i] for i in featIndices]\n",
    "    testFeatureNames = [sub.replace('_Mean', '') for sub in testFeatureNames] \n",
    "    testFeatureNames = [sub.replace('_PerCent', '') for sub in testFeatureNames]\n",
    "    testFeatureNames = [sub.replace('_meanVel', '') for sub in testFeatureNames]\n",
    "    #print('testFeatureNames: \\n',testFeatureNames)\n",
    "    #print('featIndices: \\n',featIndices)\n",
    "    testFeatures = [features[i] for i in featIndices]\n",
    "    #print('testFeatures: \\n',testFeatures)\n",
    "      \n",
    "    #Create Activity Matrix\n",
    "    #Compute the outer product to get how much activity in each pair of features\n",
    "    activityMat = pd.DataFrame(np.outer(testFeatures,testFeatures),columns=testFeatureNames,index=testFeatureNames)\n",
    "    #print('activityMat: \\n',activityMat)\n",
    "    \n",
    "    #Spearman Correlation Matrix\n",
    "    corDF = gazeDF.drop(['face_id','success','confidence','frame'],axis=1).corr(method='spearman')\n",
    "    #print('corDF: \\n',corDF)\n",
    "    #print('corDF.columns: \\n',corDF.columns)\n",
    "    nanLessCorDF = corDF.fillna(0)\n",
    "    \n",
    "    #Partial Correlation Matrix\n",
    "    partCorrDF = gazeDF.drop(['face_id','success','confidence','frame'],axis=1).pcorr()\n",
    "    #print('partCorrDF: \\n',partCorrDF)\n",
    "    #print('partCorrDF.columns: \\n',partCorrDF.columns)\n",
    "    nanLessPartCorDF = partCorrDF.fillna(0)\n",
    "    \n",
    "    #Now add the Spearman correlation features to the current lists\n",
    "    corrFeatureDF = nanLessCorDF.where(np.triu(np.ones(nanLessCorDF.shape),k=1).astype(bool))\n",
    "    corrFeatureDF = corrFeatureDF.stack().reset_index()\n",
    "    corrFeatureDF.columns = ['Row','Column','Value']\n",
    "    #print('corrFeatureDF: \\n',corrFeatureDF)\n",
    "    corrFeatures = corrFeatureDF.Value\n",
    "    corrFeatureNames = corrFeatureDF['Row'] + '_' + corrFeatureDF['Column']\n",
    "    #print('corrFeatureNames: ',corrFeatureNames)\n",
    "    #print('corrFeatures: \\n',corrFeatures)\n",
    "\n",
    "    \n",
    "    #Plot Correlation Matrix\n",
    "    plt.figure(figsize=(27,22))\n",
    "    sns.heatmap(nanLessCorDF, annot=False, cmap='coolwarm', center=0.0, vmin=-1, vmax=1)\n",
    "    corFileName = facePrintDir+Speaker+'_qtl_'+study+'_'+Session+'_AU_SpearCorr.png' \n",
    "    plt.savefig(corFileName, bbox_inches='tight')  \n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    #Plot Activiy Matrix\n",
    "    actFileName = facePrintDir+Speaker+'_qtl_'+study+'_'+Session+'_AU_Act.png' \n",
    "    corrplot(nanLessCorDF,activityMat,actFileName)\n",
    "    \n",
    "    return [corrFeatures,corrFeatureNames]    \n",
    "\n",
    "def genActionUnitFeatures(openFaceDF):\n",
    "    #anger_list = ['AU04_p','AU05_p','AU07_p','AU23_p']\n",
    "    #anger_int_list = ['AU04_int_Mean','AU05_int_Mean','AU07_int_Mean','AU23_int_Mean']\n",
    "    #anger_p_list = ['AU04_p_PerCent','AU05_p_PerCent','AU07_p_PerCent','AU23_p_PerCent']\n",
    "    featureNames = list()\n",
    "    features = list()\n",
    "    totalMeanPresence = 0\n",
    "    totalMeanIntensity = 0\n",
    "    #Get rid of rows where the face wasn't detected successfully\n",
    "    openFaceDF = openFaceDF.loc[openFaceDF['success']==1,:]\n",
    "    rows,cols = openFaceDF.shape\n",
    "\n",
    "    #Presence Metrics              \n",
    "    presenceFeatureNames  = [f for f in newGazeCols if \"_p\" in f]\n",
    "    for feature in presenceFeatureNames:\n",
    "        newFeatureName =  feature+'_PerCent'\n",
    "        featureNames.extend([newFeatureName])\n",
    "\n",
    "        percentFeature = np.sum(openFaceDF.loc[:,feature])/rows\n",
    "        totalMeanPresence = totalMeanPresence + percentFeature\n",
    "        features.extend([percentFeature])\n",
    "\n",
    "    #Intensity Metrics          \n",
    "    intensityFeatureNames  = [f for f in newGazeCols if \"_int\" in f]\n",
    "    for feature in intensityFeatureNames:\n",
    "    \n",
    "        newFeatureName =  feature+'_Mean'\n",
    "        featureNames.extend([newFeatureName]) \n",
    "        meanFeature = np.mean(openFaceDF.loc[:,feature])\n",
    "        totalMeanIntensity = totalMeanIntensity + meanFeature\n",
    "        features.extend([meanFeature])\n",
    "        \n",
    "        newFeatureName =  feature+'_Max'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        maxFeature = np.max(openFaceDF.loc[:,feature])\n",
    "        features.extend([maxFeature])    \n",
    "        \n",
    "        newFeatureName =  feature+'_STD'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        stdFeature = np.std(openFaceDF.loc[:,feature])\n",
    "        features.extend([stdFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_Var'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        varFeature = np.var(openFaceDF.loc[:,feature])\n",
    "        features.extend([varFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_Mode'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        modeFeature, counts = sp.stats.mode(openFaceDF.loc[:,feature])\n",
    "        features.extend([modeFeature[0]]) \n",
    "        \n",
    "        newFeatureName =  feature+'_Kur'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        kurFeature = sp.stats.kurtosis(openFaceDF.loc[:,feature])\n",
    "        features.extend([kurFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_Skew'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        skewFeature = sp.stats.skew(openFaceDF.loc[:,feature])\n",
    "        features.extend([skewFeature]) \n",
    "                \n",
    "        newFeatureName =  feature+'_qtl05'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .05)\n",
    "        features.extend([qtlFeature]) \n",
    "                        \n",
    "        newFeatureName =  feature+'_qtl10'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .10)\n",
    "        features.extend([qtlFeature]) \n",
    "                        \n",
    "        newFeatureName =  feature+'_qtl25'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .25)\n",
    "        features.extend([qtlFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_qtl50'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .50)\n",
    "        features.extend([qtlFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_qtl75'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .75)\n",
    "        features.extend([qtlFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_qtl90'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .90)\n",
    "        features.extend([qtlFeature]) \n",
    "        \n",
    "        newFeatureName =  feature+'_qtl95'\n",
    "        featureNames.extend([newFeatureName])\n",
    "        qtlFeature = np.quantile(openFaceDF.loc[:,feature], .95)\n",
    "        features.extend([qtlFeature]) \n",
    "    \n",
    "    #Global metrics        \n",
    "    featureNames.extend(['AUs_int_Mean'])\n",
    "    meanFeature = totalMeanIntensity/len(intensityFeatureNames)\n",
    "    features.extend([meanFeature])  \n",
    "    featureNames.extend(['AUs_p_Mean'])\n",
    "    meanFeature = totalMeanPresence/len(presenceFeatureNames)\n",
    "    features.extend([meanFeature]) \n",
    "    \n",
    "    return [features,featureNames]  \n",
    "    \n",
    "def heatmap(x, y, actFileName, **kwargs):\n",
    "\n",
    "    plt.figure(figsize=(22, 22))\n",
    "    \n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 32 # Use 32 colors for the diverging color palette\n",
    "        palette = sns.color_palette(\"Blues\", n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "        #print('size min: ',size_min)\n",
    "        #print('size max: ',size_max)\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 750)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "            \n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) \n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    #Square marker\n",
    "    marker = kwargs.get('marker', 's')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=[value_to_color(v) for v in color],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor', linewidth=0.1)\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "    \n",
    "    plt.setp(ax.get_xticklabels(), fontsize=8)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=8)\n",
    "\n",
    "    # Add color legend on the right side of the plot\n",
    "    if color_min < color_max:\n",
    "        ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "        col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "        bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "        bar_height = bar_y[1] - bar_y[0]\n",
    "        ax.barh(\n",
    "            y=bar_y,\n",
    "            width=[5]*len(palette), # Make bars 5 unit wide\n",
    "            left=col_x, # Make bars start at 0\n",
    "            height=bar_height,\n",
    "            color=palette,\n",
    "            linewidth=0\n",
    "        )\n",
    "        ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "        ax.grid(False) # Hide grid\n",
    "        ax.set_facecolor('white') # Make background white\n",
    "        ax.set_xticks([]) # Remove horizontal ticks\n",
    "        ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "        ax.yaxis.tick_right() # Show vertical ticks on the right \n",
    "          \n",
    "    plt.savefig(actFileName, bbox_inches='tight')     \n",
    "    plt.close()\n",
    "\n",
    "def corrplot(data, sizeMat, actFileName, size_scale=500, marker='s'):\n",
    "    corr = pd.melt(data.reset_index(), id_vars='index')\n",
    "    corr.columns = ['x', 'y', 'value']\n",
    "    #print('corr: \\n',corr)\n",
    "    activity = pd.melt(sizeMat.reset_index(), id_vars='index')\n",
    "    activity.columns = ['x', 'y', 'value']\n",
    "    #print('activity: \\n',activity)\n",
    "    heatmap(\n",
    "        corr['x'], corr['y'],actFileName,\n",
    "        color=corr['value'], color_range=[-1, 1],\n",
    "        palette=sns.color_palette(\"coolwarm\",32),\n",
    "        size=activity['value'], size_range=[0,1.0],\n",
    "        marker=marker,\n",
    "        x_order=data.columns,\n",
    "        y_order=data.columns[::-1],\n",
    "        size_scale=size_scale\n",
    "    )  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202c9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each person in the dyad find their first order features\n",
    "\n",
    "\n",
    "#Lists for ALL participants\n",
    "faceFeaturesLists = list()\n",
    "cohortPercentSuccessfulFramesList = list()\n",
    "cohortAvgConfidenceSuccessfulFrameList  = list()\n",
    "cohortSubjectSessionList  = list()\n",
    "\n",
    "for Speaker in Speakers:\n",
    "    speakerDir = InputDataDir + Speaker +'/'\n",
    "\n",
    "    # Find all the Openface file for this Speaker.\n",
    "    print('speakerDir: ',speakerDir)\n",
    "    landmarkFiles = glob.glob(speakerDir+'**/TotalLandmarks.csv', recursive=True)\n",
    "    print('landmarkFiles[0]: ',landmarkFiles)\n",
    "    print('type(landmarkFiles[0]): ',type(landmarkFiles[0]))\n",
    "\n",
    "    #Loop through all files under the directory\n",
    "    firstTrip = False\n",
    "    for faceFileName in sorted(landmarkFiles):\n",
    "        print(faceFileName)\n",
    "\n",
    "        #Read the full openface csv file\n",
    "        faceDF = pd.read_csv(faceFileName) \n",
    "        faceFeaturesNameLists = list()\n",
    "\n",
    "        #Get rid of leading blanks\n",
    "        faceCols = list(faceDF)\n",
    "        faceCols = [c.replace(' ', '') for c in faceCols]\n",
    "        faceDF.columns = faceCols\n",
    "\n",
    "        #Save the timestamps\n",
    "        timestamps = faceDF['timestamp']\n",
    "        print('type(timestamps): ',type(timestamps))\n",
    "\n",
    "        #Subset to gaze/face columns\n",
    "        gazeDF = faceDF[gazeCols]\n",
    "        gazeDF.columns = newGazeCols\n",
    "\n",
    "        #Summarize input and results\n",
    "        frames,cols = gazeDF.shape\n",
    "        print('OpenFace Video frames: ',frames)\n",
    "        successfulFrameDF = gazeDF.loc[gazeDF.loc[:,\"success\"]==1,:]\n",
    "        successfulFrameDF = successfulFrameDF.loc[successfulFrameDF.loc[:,\"confidence\"]>.88,:]\n",
    "        numSuccessfulFrames, cols = successfulFrameDF.shape\n",
    "        percentSuccessfulFrames = str(int((numSuccessfulFrames/frames)*100.0))\n",
    "        avgConfidenceSuccessfulFrames = str(int(successfulFrameDF[\"confidence\"].mean()*100.0))\n",
    "        print('OpenFace successful frames: ',numSuccessfulFrames)\n",
    "        print('Percent OpenFace successful frames: ',percentSuccessfulFrames)\n",
    "        print('Average Confidence for Successful Frames: ',avgConfidenceSuccessfulFrames)\n",
    "\n",
    "        #Lists for THIS participant\n",
    "        faceFeaturesList = [Session, Diag, Participant, Speaker,percentSuccessfulFrames,avgConfidenceSuccessfulFrames]\n",
    "        faceFeatureNamesList = ['Session', 'Diag', 'Participant', 'Speaker','percentSuccessfulFrames', 'avgConfidenceSuccessfulFrames']\n",
    "\n",
    "        #                Gaze Metrics\n",
    "        intGazeRX = (gazeDF['gaze_Rx'])\n",
    "        intGazeRY = (gazeDF['gaze_Ry'])\n",
    "\n",
    "        [features,featureNames] = genRobustMotionFeatures(intGazeRX ,gazeDF.loc[:,\"success\"],'gaze_Rx')\n",
    "        faceFeaturesList.extend(features)\n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "        [features,featureNames] = genRobustMotionFeatures(intGazeRY ,gazeDF.loc[:,\"success\"],'gaze_Ry')\n",
    "        faceFeaturesList.extend(features)    \n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "\n",
    "        #               Pose Metrics\n",
    "        intPoseRX = (gazeDF['pose_Rx'])\n",
    "        intPoseRY = (gazeDF['pose_Ry'])\n",
    "        intPoseRZ = (gazeDF['pose_Rz'])\n",
    "        [features,featureNames] = genRobustMotionFeatures(intPoseRX ,gazeDF.loc[:,\"success\"],'pose_Rx')\n",
    "        faceFeaturesList.extend(features)\n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "        [features,featureNames] = genRobustMotionFeatures(intPoseRY ,gazeDF.loc[:,\"success\"],'pose_Ry')\n",
    "        faceFeaturesList.extend(features)    \n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "        [features,featureNames] = genRobustMotionFeatures(intPoseRZ ,gazeDF.loc[:,\"success\"],'pose_Rz')\n",
    "        faceFeaturesList.extend(features)    \n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "\n",
    "        #              Face Metrics\n",
    "        [features,featureNames] = genActionUnitFeatures(gazeDF)\n",
    "        faceFeaturesList.extend(features)\n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "\n",
    "        #               FacePrint (Correlation Metrics)\n",
    "        #print('faceFeaturesList: \\n',faceFeaturesList)\n",
    "        #print('faceFeatureNamesList: \\n',faceFeatureNamesList)\n",
    "        facePrintDir = speakerDir + 'viz/'\n",
    "        [features,featureNames] = genFacePrint(gazeDF, faceFeaturesList,faceFeatureNamesList)\n",
    "        faceFeaturesList.extend(features)\n",
    "        faceFeatureNamesList.extend(featureNames)\n",
    "\n",
    "        #Append list for THIS participant to list for ALL participants\n",
    "        faceFeaturesLists.append(faceFeaturesList)\n",
    "        cohortPercentSuccessfulFramesList.append(percentSuccessfulFrames)\n",
    "        cohortAvgConfidenceSuccessfulFrameList.append(avgConfidenceSuccessfulFrames)\n",
    "        cohortSubjectSessionList.append(Session)\n",
    "\n",
    "    print(\"SubjectSessionList: \",cohortSubjectSessionList)     \n",
    "    print(\"cohortPercentSuccessfulFrameList: \",cohortPercentSuccessfulFramesList)   \n",
    "    print(\"Mean cohortPercentSuccessfulFrames: \",np.mean(np.array(cohortPercentSuccessfulFramesList).astype(int)))\n",
    "    print(\"Mean cohortAvgConfidenceSuccessfulFrameList: \",np.mean(np.array(cohortAvgConfidenceSuccessfulFrameList).astype(int)))\n",
    "\n",
    "\n",
    "    #print(\"faceFeatureNamesList: \",faceFeatureNamesList)   \n",
    "    \n",
    "allStatsDF = pd.DataFrame(faceFeaturesLists,columns=faceFeatureNamesList)\n",
    "\n",
    "outputFile = InputDataDir+'/summary_features/allRobustFaceStatsDF.csv'\n",
    "print('Saving: '+outputFile)\n",
    "allStatsDF.to_csv(outputFile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
